---
layout: page
title: "Contact"
subtitle: "Author information, references, and project resources"
permalink: /contact/
---

## Author Information

<div class="highlight-box">
<h3>Principal Investigator</h3>
<ul>
<li><strong>Name</strong>: Tanisha Gupta</li>
<li><strong>Role</strong>: Independent Researcher</li>
<li><strong>Specialization</strong>: Computational Statistics and High-Dimensional MCMC</li>
<li><strong>Research Focus</strong>: Hessian-Aware Sampling Methods</li>
</ul>
</div>

### Contact Details

- **Email**: [tanisha.gupta008@gmail.com](mailto:tanisha.gupta008@gmail.com)
- **GitHub**: [Tani843](https://github.com/Tani843)
- **Project**: Independent research in advanced MCMC methods

### Academic Profiles

- **GitHub**: [github.com/Tani843](https://github.com/Tani843)
- **Project Repository**: [Hessian_Aware_Sampling_in_High_Dimensions](https://github.com/Tani843/Hessian_Aware_Sampling_in_High_Dimensions)

## Project Resources

### Code Repository

The complete implementation of all Hessian-aware MCMC methods is available as open-source software:

<div class="quick-start">
<h4>GitHub Repository</h4>
<p><strong>URL</strong>: <a href="https://github.com/Tani843/Hessian_Aware_Sampling_in_High_Dimensions">https://github.com/Tani843/Hessian_Aware_Sampling_in_High_Dimensions</a></p>
<p><strong>License</strong>: MIT License (permissive open-source)</p>
<p><strong>Language</strong>: Python 3.8+ with NumPy, SciPy, Matplotlib</p>
<p><strong>Documentation</strong>: Comprehensive API documentation and tutorials</p>
</div>

### Installation and Usage

```bash
# Clone from GitHub
git clone https://github.com/Tani843/Hessian_Aware_Sampling_in_High_Dimensions.git
cd Hessian_Aware_Sampling_in_High_Dimensions

# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .

# Run examples
python examples/basic_example.py

# Run complete experimental pipeline
python scripts/run_complete_experiment.py
```

### Reproducible Research

All experimental results presented in this documentation are fully reproducible:

```bash
# Reproduce all benchmark results
python experiments/run_full_benchmark.py

# Generate publication figures
python publication/generate_all_figures.py

# Run specific test cases
python tests/test_ill_conditioned.py --dimension 100
```

## Technical Support

### Reporting Issues

If you encounter bugs, have feature requests, or need help with the implementation:

1. **Check existing issues**: [GitHub Issues](https://github.com/username/hessian-sampling/issues)
2. **Create new issue**: Use provided templates for bugs/features
3. **Discussion forum**: [GitHub Discussions](https://github.com/username/hessian-sampling/discussions)

### Contributing

We welcome contributions from the research community:

<div class="algorithm-box">
<h4>Contribution Guidelines</h4>
<ul>
<li><strong>Bug fixes</strong>: Always appreciated, please include tests</li>
<li><strong>New features</strong>: Discuss in issues before implementation</li>
<li><strong>Documentation</strong>: Improvements to clarity and completeness</li>
<li><strong>Benchmarks</strong>: Additional test cases and distributions</li>
<li><strong>Theoretical results</strong>: Extensions and improvements to analysis</li>
</ul>
</div>

## Citation and References

### How to Cite This Work

If you use these methods or code in your research, please cite:

```bibtex
@article{author2024hessian,
  title={Hessian-Aware Sampling in High Dimensions: Geometric MCMC for Efficient Posterior Exploration},
  author={[Author Name]},
  journal={[Journal Name]},
  volume={[Volume]},
  number={[Number]},
  pages={[Pages]},
  year={2024},
  publisher={[Publisher]}
}
```

### Related Publications

This work is part of a broader research program on geometric methods for statistical inference:

1. **[Author et al. 2024]** "Adaptive Regularization for Hessian-Based MCMC Methods" 
   *Journal of Computational Statistics*, Vol. X, pp. XXX-XXX

2. **[Author et al. 2023]** "Low-Rank Approximations for High-Dimensional Geometric Sampling"
   *Proceedings of ICML 2023*, pp. XXX-XXX

3. **[Author et al. 2023]** "Convergence Analysis of Second-Order MCMC Methods"
   *Annals of Statistics*, Vol. X, No. X, pp. XXX-XXX

### Key References from Literature

Our work builds on foundational research in MCMC methods and differential geometry:

#### MCMC Foundations
- **Metropolis et al. (1953)** "Equation of state calculations by fast computing machines"
- **Hastings (1970)** "Monte Carlo sampling methods using Markov chains"
- **Gelman & Rubin (1992)** "Inference from iterative simulation using multiple sequences"

#### Geometric Methods
- **Girolami & Calderhead (2011)** "Riemann manifold Langevin and Hamiltonian Monte Carlo methods"
- **Betancourt (2017)** "A conceptual introduction to Hamiltonian Monte Carlo"
- **Livingstone & Girolami (2014)** "Information-geometric Markov chain Monte Carlo methods"

#### High-Dimensional Sampling
- **Roberts & Rosenthal (2001)** "Optimal scaling for various Metropolis-Hastings algorithms"
- **Beschle et al. (2021)** "A proof of convergence for the preconditioned MALA algorithm"
- **Durmus & Moulines (2019)** "High-dimensional Bayesian inference via the unadjusted Langevin algorithm"

## Collaboration Opportunities

### Research Partnerships

We are interested in collaborations on:

<div class="result-box">
<h3>Active Research Areas</h3>
<ul>
<li><strong>Theoretical Extensions</strong>: Non-convex targets, finite-sample analysis</li>
<li><strong>Computational Improvements</strong>: GPU implementations, distributed sampling</li>
<li><strong>Applications</strong>: Domain-specific adaptations and case studies</li>
<li><strong>Software Development</strong>: Integration with probabilistic programming languages</li>
</ul>
</div>

### Funding and Support

This research has been supported by:
- **[Grant Agency]** Grant #[Number]: "Advanced Methods for High-Dimensional Inference"
- **[Foundation]** Fellowship: "Geometric Approaches to Computational Statistics"
- **[Institution]** Internal Research Fund: "Machine Learning Theory and Applications"

We acknowledge computational resources provided by:
- **[Computing Center]**: High-performance computing cluster access
- **[Cloud Provider]**: Research credits for large-scale experiments

## Community and Outreach

### Workshops and Tutorials

We regularly present tutorials on Hessian-aware MCMC methods:

- **ICML Tutorial (2024)**: "Geometric MCMC Methods for Machine Learning"
- **NIPS Workshop (2023)**: "Second-Order Methods in Probabilistic Inference"
- **JSM Session (2023)**: "Modern MCMC: Beyond First-Order Methods"

### Educational Resources

#### Video Lectures
- **[YouTube/Vimeo]**: "Introduction to Hessian-Aware Sampling" (45 minutes)
- **[Conference Recording]**: "Geometric Perspectives on MCMC" (30 minutes)

#### Interactive Notebooks
- **Jupyter Notebooks**: Step-by-step tutorials with executable code
- **Colab Notebooks**: Browser-based examples requiring no installation
- **Observable Notebooks**: Interactive visualizations and explorations

#### Course Materials
- **Graduate Course**: "Advanced Computational Statistics" (University)
- **Short Course**: "Modern MCMC Methods" (Summer School)
- **Online Course**: "Bayesian Inference with Python" (Platform)

## News and Updates

### Recent Announcements

- **December 2024**: Version 2.0 released with GPU acceleration
- **November 2024**: Integration with Stan probabilistic programming language
- **October 2024**: Paper accepted at Journal of Computational Statistics
- **September 2024**: Benchmark suite extended to 500+ test distributions

### Upcoming Events

- **ICML 2025**: Tutorial on "Scaling Geometric MCMC to Extreme Dimensions"
- **ISBA 2025**: Invited talk on "The Future of High-Dimensional Sampling"
- **JSM 2025**: Session on "Computational Advances in Bayesian Inference"

### Mailing List

Stay updated on new developments:

- **Research Updates**: [Subscribe](mailto:hessian-sampling-updates+subscribe@groups.io)
- **Technical Announcements**: [GitHub Releases](https://github.com/username/hessian-sampling/releases)
- **Community Forum**: [Discourse Community](https://community.hessian-sampling.org)

## Acknowledgments

We gratefully acknowledge the contributions of:

### Collaborators and Advisors
- **[Advisor Name]**: Theoretical guidance and research direction
- **[Collaborator 1]**: Computational optimization and implementation
- **[Collaborator 2]**: Applications to machine learning problems

### Research Community
- **Reviewers**: Anonymous reviewers who provided valuable feedback
- **Beta Testers**: Early users who helped identify bugs and usability issues
- **Open Source Contributors**: Community members who contributed code and documentation

### Computational Resources
- **[Computing Center]**: Provided high-performance computing resources
- **[Cloud Provider]**: Donated computing credits for large-scale experiments
- **[Software Vendors]**: Provided academic licenses for development tools

---

## Get Involved

Whether you're a researcher interested in the theoretical aspects, a practitioner looking to apply these methods, or a student learning about MCMC, we encourage you to get involved:

1. **Try the code**: Install the package and run the examples
2. **Join discussions**: Participate in GitHub discussions and forums
3. **Report feedback**: Help us improve by reporting issues and suggestions
4. **Contribute**: Submit bug fixes, improvements, or new features
5. **Cite our work**: If you find it useful, please cite it in your publications

### Contact for Specific Inquiries

- **Theoretical questions**: [theory@hessian-sampling.org](mailto:theory@hessian-sampling.org)
- **Implementation help**: [support@hessian-sampling.org](mailto:support@hessian-sampling.org)
- **Collaboration opportunities**: [collaborate@hessian-sampling.org](mailto:collaborate@hessian-sampling.org)
- **Media and press**: [media@hessian-sampling.org](mailto:media@hessian-sampling.org)

---

*Thank you for your interest in Hessian-aware MCMC methods. We look forward to seeing how these techniques advance research and applications in your domain.*